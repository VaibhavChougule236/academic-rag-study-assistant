{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084d9f8b-d778-4bf6-8594-c6d8119f4014",
   "metadata": {},
   "source": [
    "# Academic RAG Study Assistant\n",
    "## Subject: Database Management Systems (DBMS)\n",
    "### Part 1: Data Collection & Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09d129-7a59-4fa8-a4ea-64641bd28920",
   "metadata": {},
   "source": [
    "# Part 1: Data Collection & Understanding\n",
    "\n",
    "## Subject\n",
    "Database Management Systems (DBMS)\n",
    "\n",
    "## Documents Collected\n",
    "Total PDFs: 5  \n",
    "Total Pages: 700+\n",
    "\n",
    "## Topics Covered\n",
    "- Normalization\n",
    "- ACID Properties\n",
    "- Transactions\n",
    "- Concurrency Control\n",
    "- Indexing (B-Tree, Hash)\n",
    "- SQL & Relational Model\n",
    "\n",
    "## Document Types\n",
    "All documents are text-based PDFs.\n",
    "\n",
    "## Observed Challenges\n",
    "\n",
    "1. Tables lose column formatting during text extraction.\n",
    "2. SQL code blocks lose indentation.\n",
    "3. Diagrams (ER models) are not extracted.\n",
    "4. Headings merge with paragraph text.\n",
    "5. Mathematical symbols lose formatting.\n",
    "\n",
    "## Data Structure Observed\n",
    "Documents are structured as:\n",
    "- Chapters\n",
    "- Sections\n",
    "- Subsections\n",
    "- Bullet points\n",
    "- Definitions\n",
    "\n",
    "## Data Quality Issues\n",
    "- Some formatting inconsistencies\n",
    "- Broken line spacing\n",
    "- Table alignment issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3acdcba6-c3ab-43bb-b07b-116dcf912373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting: 279_DBMS Complete1.pdf\n",
      "Extracting: DATABASE MANAGEMENT SYSTEMS.pdf\n",
      "Extracting: Database-Management-System.pdf\n",
      "Extracting: DBMS.pdf\n",
      "Extracting: DBMSI-III.pdf\n",
      "\n",
      "Total Documents Loaded: 5\n",
      "Total characters in full_text: 877316\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "\n",
    "data_path = \"../data\"\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            content = page.extract_text()\n",
    "            if content:\n",
    "                text += content + \"\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "all_documents = {}\n",
    "\n",
    "# Loop through all PDFs\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        full_path = os.path.join(data_path, file)\n",
    "        print(f\"Extracting: {file}\")\n",
    "        all_documents[file] = extract_text_from_pdf(full_path)\n",
    "\n",
    "print(\"\\nTotal Documents Loaded:\", len(all_documents))\n",
    "\n",
    "\n",
    "full_text = \"\"\n",
    "\n",
    "for doc in all_documents.values():\n",
    "    full_text += doc + \"\\n\"\n",
    "\n",
    "print(\"Total characters in full_text:\", len(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09459f62-4a4a-4363-99de-e5f2b45bb4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters Across All PDFs: 877311\n",
      "Approximate Pages: 877311\n"
     ]
    }
   ],
   "source": [
    "total_chars = sum(len(text) for text in all_documents.values())\n",
    "\n",
    "print(\"Total Characters Across All PDFs:\", total_chars)\n",
    "print(\"Approximate Pages:\", total_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665a1a4-8d99-4b75-9bb9-84ef8b05a036",
   "metadata": {},
   "source": [
    "# Part 2: Baseline RAG Evaluation\n",
    "\n",
    "## Observations\n",
    "\n",
    "- Definition-based questions performed well.\n",
    "- Some conceptual answers were partially incomplete.\n",
    "- Retrieval worked better when keywords were clear.\n",
    "- Fixed-size chunking sometimes broke logical flow.\n",
    "\n",
    "## Strengths\n",
    "- Simple implementation\n",
    "- Fast retrieval\n",
    "- Lightweight\n",
    "\n",
    "## Weaknesses\n",
    "- Chunk boundaries may split definitions\n",
    "- LLM sometimes repeats sentences\n",
    "- Limited context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088a76ff-391e-457f-bb34-88db1a2b2a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combined characters: 877495\n"
     ]
    }
   ],
   "source": [
    "# Combine all PDFs into one large text\n",
    "\n",
    "combined_text = \"\"\n",
    "\n",
    "for file, text in all_documents.items():\n",
    "    combined_text += f\"\\n\\n===== {file} =====\\n\\n\"\n",
    "    combined_text += text\n",
    "\n",
    "print(\"Total combined characters:\", len(combined_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a71abad-8172-4bcf-ada9-7b0a2c573200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 2194\n"
     ]
    }
   ],
   "source": [
    "def fixed_chunking(text, chunk_size=500, overlap=100):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "        \n",
    "    return chunks\n",
    "\n",
    "chunks = fixed_chunking(combined_text)\n",
    "\n",
    "print(\"Total chunks created:\", len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bcb5151-905f-4ef4-9780-3f116af59fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\OneDrive\\Desktop\\sankey-solutions-assignments\\AI-powered_study_assistant-AIML-Assignment\\rag_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|█████████████████████| 103/103 [00:00<00:00, 110.96it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    return embedding_model.encode(text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a69bdf-6c90-4c9d-ae2a-8f6ef4f16098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks stored successfully.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "try:\n",
    "    chroma_client.delete_collection(\"baseline_rag\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "collection = chroma_client.create_collection(\"baseline_rag\")\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    collection.add(\n",
    "        documents=[chunk],\n",
    "        embeddings=[get_embedding(chunk)],\n",
    "        ids=[str(i)]\n",
    "    )\n",
    "\n",
    "print(\"Chunks stored successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "021965bd-0062-4d59-8433-76aa16979b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query, top_k=3):\n",
    "    results = collection.query(\n",
    "        query_embeddings=[get_embedding(query)],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    return results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264ed3d5-5c8b-40c9-8d5d-85051f2a9fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\OneDrive\\Desktop\\sankey-solutions-assignments\\AI-powered_study_assistant-AIML-Assignment\\rag_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vaibh\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|███████████████████████████| 282/282 [00:02<00:00, 140.86it/s, Materializing param=shared.weight]\n",
      "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "# import torch\n",
    "\n",
    "# model_name = \"google/flan-t5-small\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ba3c51-4edf-49c7-b603-576ba37bc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    context = \"\\n\\n\".join(retrieve_chunks(query))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a DBMS study assistant.\n",
    "\n",
    "Using ONLY the context below, provide a clear and complete explanation\n",
    "in 3-5 sentences.\n",
    "\n",
    "If the answer is not found, say: Not found in materials.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e896c64-5a43-4450-8bf5-491200e8110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization is the process of organizing the data in the database.\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(\"What is normalization?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63b5b050-7615-422e-a595-ce51d046a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A database management system is a computerized record-keeping system. It is a repository or a container for collection of computerized data files. The overall purpose of DBMS is to allow he users to define, store, retrieve and update the information contained in the database on demand.\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(\"What is DBMS?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "597a64b3-57c2-49f4-a6a3-984b88e8bdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test questions: 10\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    \"What is normalization?\",\n",
    "    \"Explain first normal form.\",\n",
    "    \"What are ACID properties?\",\n",
    "    \"What is a transaction in DBMS?\",\n",
    "    \"What causes deadlock?\",\n",
    "    \"Explain B-tree index.\",\n",
    "    \"Difference between DELETE and TRUNCATE?\",\n",
    "    \"What is two-phase locking?\",\n",
    "    \"What is functional dependency?\",\n",
    "    \"When should we use hash index instead of B-tree?\"\n",
    "]\n",
    "\n",
    "print(\"Total test questions:\", len(test_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cdef106-01fe-4ae3-bd9d-a83c23af8261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: What is normalization?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "Normalization is the process of organizing the data in the database.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Explain first normal form.\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "First normal form is the first normal form based on FDs.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What are ACID properties?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "ACID Properties are used for maintaining the integrity of database during transaction processing.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is a transaction in DBMS?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "A transaction is a set of logically related operations.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What causes deadlock?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "If more than one process takes action, the deadlock detection algorithm can repeatedly trigger.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Explain B-tree index.\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "B-tree index is a file that is indexed.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Difference between DELETE and TRUNCATE?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "TRUNCATE is logically (though not physically) equivalent to the DELETE FROM mytable statement (without a WHERE clause).\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is two-phase locking?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "The two-phase locking protocol divides the execution phase of the transaction into three parts.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is functional dependency?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "A functional dependency (FD) is a particular relationship between two attributes.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: When should we use hash index instead of B-tree?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "B+-tree indices are an alternative to indexed-sequential files.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for q in test_questions:\n",
    "    print(\"\\nQUESTION:\", q)\n",
    "    \n",
    "    print(\"\\n--- Fixed Chunking ---\")\n",
    "    print(generate_answer(q))\n",
    "    \n",
    "    \n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8669450-76d6-43be-834b-c6bd81314f4f",
   "metadata": {},
   "source": [
    "# Part 3: Experimentation & Comparison (40%)\n",
    "\n",
    "This section evaluates different design choices in the RAG pipeline and analyzes their impact on retrieval quality and answer generation.\n",
    "\n",
    "The goal is to:\n",
    "- Compare performance systematically  \n",
    "- Identify trade-offs  \n",
    "- Draw meaningful conclusions  \n",
    "- Justify final design decisions  \n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "# Experiment 1: Chunking Strategy Comparison\n",
    "\n",
    "## Objective\n",
    "\n",
    "To analyze how different chunking strategies affect:\n",
    "- Retrieval relevance  \n",
    "- Context preservation  \n",
    "- Answer quality  \n",
    "- Overall system performance  \n",
    "\n",
    "Since DBMS textbooks contain:\n",
    "- Definitions  \n",
    "- Structured explanations  \n",
    "- Tables  \n",
    "- SQL examples  \n",
    "- Theoretical descriptions  \n",
    "\n",
    "Chunking strategy may significantly impact how context is preserved.\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Chunking Strategies Tested\n",
    "\n",
    "### 1) Fixed-Size Chunking (Baseline)\n",
    "\n",
    "- Chunk size: 500 characters  \n",
    "- Overlap: 100 characters  \n",
    "- Splits text purely by character count  \n",
    "\n",
    "Advantages:\n",
    "- Simple and fast  \n",
    "- Easy to implement  \n",
    "- Consistent chunk size  \n",
    "\n",
    "Disadvantages:\n",
    "- May split sentences  \n",
    "- May break definitions  \n",
    "- Can lose semantic meaning  \n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "### 2) Sentence-Based Chunking\n",
    "\n",
    "- Text split at sentence boundaries  \n",
    "- Chunks built by grouping complete sentences  \n",
    "- Maximum chunk size limit applied  \n",
    "\n",
    "Advantages:\n",
    "- Preserves semantic meaning  \n",
    "- Avoids broken sentences  \n",
    "- Better for conceptual subjects like DBMS  \n",
    "\n",
    "Disadvantages:\n",
    "- Chunk sizes may vary  \n",
    "- Slightly slower than fixed chunking  \n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Methodology\n",
    "\n",
    "- Used same 10 DBMS test questions  \n",
    "- Used same embedding model  \n",
    "- Used same LLM (flan-t5-small)  \n",
    "- Retrieval top-k = 5  \n",
    "- Evaluated on:\n",
    "\n",
    "  - Relevance (1–5)\n",
    "  - Answer Quality (1–5)\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5e167b-c98b-4de1-a583-3d51731fae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sentence_chunking(text, max_chunk_size=500):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= max_chunk_size:\n",
    "            current_chunk += \" \" + sentence\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba61cde-3086-42c6-b2cd-ab3757679750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence chunks: 2033\n"
     ]
    }
   ],
   "source": [
    "sentence_chunks = sentence_chunking(full_text)\n",
    "print(\"Sentence chunks:\", len(sentence_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f70b7e62-2685-4ab4-a503-81d47e2ac89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_sentence = chroma_client.get_or_create_collection(\"sentence_rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "283c257f-e273-4b97-8542-095c07f3d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_chunks = sentence_chunking(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b26217e-6b4f-42c1-b889-58c21b3f7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(sentence_chunks):\n",
    "    collection_sentence.add(\n",
    "        documents=[chunk],\n",
    "        embeddings=[get_embedding(chunk)],\n",
    "        ids=[str(i)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8047b72-130e-414f-adf2-57b27576d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks_sentence(query, k=5):\n",
    "    results = collection_sentence.query(\n",
    "        query_embeddings=[get_embedding(query)],\n",
    "        n_results=k\n",
    "    )\n",
    "    return results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fc6fade-4d64-441f-b5dc-16aaccaba39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_sentence(query):\n",
    "    context = \"\\n\\n\".join(retrieve_chunks_sentence(query))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Answer the question using only the context below.\n",
    "Provide a clear explanation in 3-5 sentences.\n",
    "If not found, say: Not found in materials.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3b210ed-1c5c-4583-bd30-6ec3e553637a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test questions: 10\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    \"What is normalization?\",\n",
    "    \"Explain first normal form.\",\n",
    "    \"What are ACID properties?\",\n",
    "    \"What is a transaction in DBMS?\",\n",
    "    \"What causes deadlock?\",\n",
    "    \"Explain B-tree index.\",\n",
    "    \"Difference between DELETE and TRUNCATE?\",\n",
    "    \"What is two-phase locking?\",\n",
    "    \"What is functional dependency?\",\n",
    "    \"When should we use hash index instead of B-tree?\"\n",
    "]\n",
    "\n",
    "print(\"Total test questions:\", len(test_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2abfa0f4-1395-4541-aadd-5c2465f94a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: What is normalization?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "Normalization is the process of organizing the data in the database.\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "Normalization is a systematic approach of decomposing tables to eliminate data redundancy and undesirable characteristics like insertion. deletion and modification. o The poor database design gives rise to many anomalies. This anomalies can be avoided by a process called Decomposition process or “Normalization”.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Explain first normal form.\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "First normal form is the first normal form based on FDs.\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "First normal form is the first normal form based on FDs.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What are ACID properties?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "ACID Properties are used for maintaining the integrity of database during transaction processing.\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "A transaction is a unit of operation. It must be executed in isolation from other transactions.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is a transaction in DBMS?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "A transaction is a set of logically related operations.\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "A transaction is a logical unit of processing in a DBMS which entails one or more database access operation.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What causes deadlock?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "If more than one process takes action, the deadlock detection algorithm can repeatedly trigger.\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "A deadlock is a condition in which two or more transactions are unable to items in unfair, giving priority to some proceed because each is waiting for one of the other to do transactions over others.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Explain B-tree index.\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "B-tree index is a file that is indexed.\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "B-tree index files are a type of tree index file. They are used to find the search keys in a tree. They are not indexed-sequential files.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Difference between DELETE and TRUNCATE?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "TRUNCATE is logically (though not physically) equivalent to the DELETE FROM mytable statement (without a WHERE clause).\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "                                                                          \n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is two-phase locking?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "The two-phase locking protocol divides the execution phase of the transaction into three parts.\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "Binary locks are the most common type of lock.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is functional dependency?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "A functional dependency (FD) is a particular relationship between two attributes.\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "A functional dependency is a particular relationship between two attributes.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: When should we use hash index instead of B-tree?\n",
      "\n",
      "--- Fixed Chunking ---\n",
      "B+-tree indices are an alternative to indexed-sequential files.\n",
      "\n",
      "--- Sentence Chunking ---\n",
      "A hash file organization is a file organization that provides direct access to records that indexing provides.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for q in test_questions:\n",
    "    print(\"\\nQUESTION:\", q)\n",
    "    \n",
    "    print(\"\\n--- Fixed Chunking ---\")\n",
    "    print(generate_answer(q))\n",
    "    \n",
    "    print(\"\\n--- Sentence Chunking ---\")\n",
    "    print(generate_answer_sentence(q))\n",
    "    \n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba5125f-8ac4-487d-8dff-0b90b311bf4b",
   "metadata": {},
   "source": [
    "## Experiment 1 Results – Chunking Strategy Comparison\n",
    "\n",
    "| Question | Fixed Relevance | Fixed Quality | Sentence Relevance | Sentence Quality |\n",
    "|----------|----------------|--------------|-------------------|------------------|\n",
    "| Normalization | 4 | 4 | 4 | 3 |\n",
    "| First Normal Form | 2 | 2 | 5 | 4 |\n",
    "| ACID Properties | 3 | 3 | 1 | 1 |\n",
    "| Transaction | 4 | 4 | 4 | 4 |\n",
    "| Deadlock | 3 | 2 | 1 | 1 |\n",
    "| B-tree Index | 3 | 2 | 1 | 1 |\n",
    "| DELETE vs TRUNCATE | 3 | 2 | 1 | 1 |\n",
    "| Two-Phase Locking | 3 | 2 | 5 | 4 |\n",
    "| Functional Dependency | 4 | 4 | 4 | 4 |\n",
    "| Hash vs B-tree | 2 | 2 | 2 | 2 |\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Observations\n",
    "\n",
    "1. Sentence-based chunking improved conceptual explanations such as:\n",
    "   - First Normal Form\n",
    "   - Two-Phase Locking\n",
    "\n",
    "2. Fixed-size chunking produced more stable outputs across most topics.\n",
    "\n",
    "3. Sentence chunking sometimes retrieved irrelevant or incomplete context, especially for:\n",
    "   - ACID properties\n",
    "   - Deadlock\n",
    "   - B-tree index\n",
    "   - DELETE vs TRUNCATE\n",
    "\n",
    "4. Sentence chunking occasionally introduced repetition and redundant text.\n",
    "\n",
    "5. Fixed-size chunking sometimes cut sentences but maintained consistent retrieval alignment.\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Analysis\n",
    "\n",
    "DBMS textbooks contain mixed content types including:\n",
    "\n",
    "- Theoretical definitions\n",
    "- Structured bullet lists\n",
    "- Tables\n",
    "- Index descriptions\n",
    "- Transactional concepts\n",
    "\n",
    "Sentence-based chunking preserved theoretical definitions better but created retrieval instability in structured and list-based sections.\n",
    "\n",
    "Fixed-size chunking provided more consistent retrieval across diverse DBMS topics.\n",
    "\n",
    "Therefore, for this DBMS dataset, fixed-size chunking demonstrated more reliable overall performance despite minor sentence-breaking issues.\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Conclusion – Chunking Strategy Decision\n",
    "\n",
    "Although sentence chunking improved certain conceptual explanations, it introduced instability and retrieval noise in several other areas.\n",
    "\n",
    "Given the overall consistency and reliability of outputs, fixed-size chunking is selected as the final chunking strategy for the DBMS RAG system.\n",
    "\n",
    "This decision is based on empirical evaluation rather than assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a23da-efb8-4419-89b0-c5e2966e7921",
   "metadata": {},
   "source": [
    "# Experiment 2: Prompt Engineering Comparison\n",
    "\n",
    "## Objective\n",
    "\n",
    "To evaluate the impact of prompt design on answer quality.\n",
    "\n",
    "Prompting significantly influences:\n",
    "- Explanation depth  \n",
    "- Structure  \n",
    "- Clarity  \n",
    "- Faithfulness to context  \n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Prompt Strategies Tested\n",
    "\n",
    "### 1) Basic Prompt\n",
    "\n",
    "Simple instruction:\n",
    "\"Answer using only the context below.\"\n",
    "\n",
    "Characteristics:\n",
    "- Short answers  \n",
    "- Direct extraction  \n",
    "- Minimal elaboration  \n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "### 2) Improved Prompt\n",
    "\n",
    "Structured instruction:\n",
    "- Role assignment (DBMS Study Assistant)\n",
    "- Instruction to provide 3–5 sentence explanation\n",
    "- Explicit grounding in context\n",
    "- Clear fallback instruction\n",
    "\n",
    "Expected Benefits:\n",
    "- Better structured answers  \n",
    "- Slightly more explanation  \n",
    "- Improved clarity  \n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Methodology\n",
    "\n",
    "- Same 10 questions  \n",
    "- Same retrieval chunks  \n",
    "- Same embedding model  \n",
    "- Only prompt changed  \n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Observations\n",
    "\n",
    "- Improved prompt generated more complete explanations.\n",
    "- Basic prompt produced shorter but accurate answers.\n",
    "- Structured prompts improved clarity.\n",
    "- No hallucination observed due to strict grounding instruction.\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Analysis\n",
    "\n",
    "Prompt engineering significantly influences answer readability.\n",
    "\n",
    "For academic RAG systems:\n",
    "- Clear instructions improve answer structure.\n",
    "- Role-based prompting improves explanation quality.\n",
    "- However, model size limits overall depth.\n",
    "\n",
    "Improved prompting is beneficial but cannot compensate for weak retrieval.\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Final Decision for Production System\n",
    "\n",
    "Based on experiments:\n",
    "\n",
    "- Sentence-based chunking selected.\n",
    "- Improved structured prompt selected.\n",
    "- flan-t5-small retained due to free and lightweight constraint.\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "## Key Insights from Experimentation\n",
    "\n",
    "1. Retrieval quality matters more than model size.\n",
    "2. Chunking strategy strongly affects conceptual question performance.\n",
    "3. Prompt design influences answer clarity but not retrieval.\n",
    "4. RAG performance depends heavily on context alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abefdc33-be2a-4cb7-ab45-95a84ae826a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Basic Prompt Version\n",
    "# -----------------------------\n",
    "\n",
    "def generate_answer_basic(query):\n",
    "    context = \"\\n\\n\".join(retrieve_chunks(query))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Answer the question using only the context below.\n",
    "If not found, say: Not found in materials.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c2d44f7-aeca-4982-a061-460f20f726d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_answer_optimized(query):\n",
    "    context = \"\\n\\n\".join(retrieve_chunks(query))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Answer the question clearly and completely using ONLY the context below.\n",
    "Write 2-4 complete sentences.\n",
    "Do not repeat phrases.\n",
    "If the answer is not present, say: Not found in materials.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=120,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3d50a13-e576-427e-ac15-3d10095e124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: What is normalization?\n",
      "\n",
      "--- Basic Prompt ---\n",
      "the process of organizing the data in the database\n",
      "\n",
      "--- Improved Prompt ---\n",
      "The process of organizing the data in the database.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Explain first normal form.\n",
      "\n",
      "--- Basic Prompt ---\n",
      "1NF\n",
      "\n",
      "--- Improved Prompt ---\n",
      "1NF\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What are ACID properties?\n",
      "\n",
      "--- Basic Prompt ---\n",
      "ACID Properties are used for maintaining the integrity of database during transaction processing\n",
      "\n",
      "--- Improved Prompt ---\n",
      "Atomicity, Consistency, Isolation, and Durability\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is a transaction in DBMS?\n",
      "\n",
      "--- Basic Prompt ---\n",
      "a set of logically related operations\n",
      "\n",
      "--- Improved Prompt ---\n",
      "A logical unit of processing.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What causes deadlock?\n",
      "\n",
      "--- Basic Prompt ---\n",
      "Circular waiting\n",
      "\n",
      "--- Improved Prompt ---\n",
      "Circular waiting.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Explain B-tree index.\n",
      "\n",
      "--- Basic Prompt ---\n",
      "B+ Tree Index\n",
      "\n",
      "--- Improved Prompt ---\n",
      "B-tree index is an alternative to indexed-sequential files.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Difference between DELETE and TRUNCATE?\n",
      "\n",
      "--- Basic Prompt ---\n",
      "TRUNCATE\n",
      "\n",
      "--- Improved Prompt ---\n",
      "DELETE vs TRUNCATE\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is two-phase locking?\n",
      "\n",
      "--- Basic Prompt ---\n",
      "TWO-PHASE LOCKING\n",
      "\n",
      "--- Improved Prompt ---\n",
      "TWO-PHASE LOCKING\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is functional dependency?\n",
      "\n",
      "--- Basic Prompt ---\n",
      "a particular relationship between two attributes\n",
      "\n",
      "--- Improved Prompt ---\n",
      "a particular relationship between two attributes\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: When should we use hash index instead of B-tree?\n",
      "\n",
      "--- Basic Prompt ---\n",
      "Sometimes possible to find search-key B+ Tree Index\n",
      "\n",
      "--- Improved Prompt ---\n",
      "Implementation is harder than B+-Trees.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for q in test_questions:\n",
    "    print(\"\\nQUESTION:\", q)\n",
    "    \n",
    "    print(\"\\n--- Basic Prompt ---\")\n",
    "    print(generate_answer_basic(q))\n",
    "    \n",
    "    print(\"\\n--- Improved Prompt ---\")\n",
    "    print(generate_answer_optimized(q))\n",
    "    \n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78349670-cd88-4971-b7a4-cde0b0598d00",
   "metadata": {},
   "source": [
    "# Experiment 3: Retrieval Strategy (Top-k Comparison)\n",
    "\n",
    "\n",
    "In the previous experiments, I noticed that even after improving the model and prompt, some answers were still incorrect or incomplete.\n",
    "\n",
    "After observing the outputs carefully, I understood that the main issue is not only the model, but also the retrieved context.\n",
    "\n",
    "Sometimes:\n",
    "- The retrieved chunks were not fully relevant.\n",
    "- Important information was missing.\n",
    "- Too much unnecessary text confused the model.\n",
    "\n",
    "So I decided to test whether changing the number of retrieved chunks (top-k value) can improve the answer quality.\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "The goal of this experiment is to check how different top-k values affect:\n",
    "\n",
    "- Accuracy of answers\n",
    "- Completeness of explanation\n",
    "- Noise in the context\n",
    "- Overall clarity of the response\n",
    "\n",
    "---\n",
    "\n",
    "## My Hypothesis\n",
    "\n",
    "I expect the following:\n",
    "\n",
    "- If k = 3 → Model may miss important information (too little context).\n",
    "- If k = 8 → Model may get confused because of too much context.\n",
    "- If k = 5 → It might give a balanced and better answer.\n",
    "\n",
    "---\n",
    "\n",
    "## Experimental Setup\n",
    "\n",
    "In this experiment, I will test:\n",
    "\n",
    "- Top-k = 3  \n",
    "- Top-k = 5  \n",
    "- Top-k = 8  \n",
    "\n",
    "Everything else will remain same:\n",
    "\n",
    "- Same chunking strategy (Fixed-size)\n",
    "- Same embedding model\n",
    "- Same prompt\n",
    "- Same LLM (flan-t5-base)\n",
    "- Same 10 DBMS questions\n",
    "\n",
    "Only the number of retrieved chunks is changed.\n",
    "\n",
    "---\n",
    "\n",
    "## What I will evaluate\n",
    "\n",
    "For each k value, I will check:\n",
    "\n",
    "- Whether the answer is correct\n",
    "- Whether it is complete\n",
    "- Whether it contains unnecessary or confusing information\n",
    "- Whether increasing k improves or degrades the response\n",
    "\n",
    "Based on the results, I will select the best top-k value for the final system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79cefbc9-bf57-47e1-b8be-f6871d4d2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks_k(query, k=5):\n",
    "    results = collection.query(\n",
    "        query_embeddings=[get_embedding(query)],\n",
    "        n_results=k\n",
    "    )\n",
    "    return results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97cc344e-817e-4384-8ca4-ac4e3e0e8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_k(query, k):\n",
    "    context = \"\\n\\n\".join(retrieve_chunks_k(query, k))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Answer clearly using ONLY the context below.\n",
    "Write 2-4 complete sentences.\n",
    "If not found, say: Not found in materials.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13fc3701-bfa8-4ba0-b5bb-10b417c4705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: What is normalization?\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "the process of organizing the data in the database\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "data redundancy, insertion anomaly, update anomaly & deletion anomaly\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "data redundancy, insertion anomaly, update anomaly & deletion anomaly\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Explain first normal form.\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "1NF\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "DATABASE MANAGEMENT SYSTEMS Page 2\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "DATABASE MANAGEMENT SYSTEMS Page 2\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What are ACID properties?\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "ACID Properties are used for maintaining the integrity of database during transaction processing.\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "el, data are stored as tables. However, the physical storage of the data is independent\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "el, data are stored as tables. However, the physical storage of the data is independent\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is a transaction in DBMS?\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "A logical unit of processing\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "DATABASE MANAGEMENT SYSTEMS Page 125 UNIT-4 TRANSACTION MANAGEMENT IN DBMS:  A transaction is a set of logically related operations.  Now that we understand what is transaction, we should understand what are the problems associated with it.  The main problem that can happen during a transaction is that the transaction can fail before finishing the all the operations in the set. part of the database system, since it enables the database to handle data sizes that are much larger than the size of main memory.\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "DATABASE MANAGEMENT SYSTEMS Page 125 UNIT-4 TRANSACTION MANAGEMENT IN DBMS:  A transaction is a set of logically related operations.  Now that we understand what is transaction, we should understand what are the problems associated with it.  The main problem that can happen during a transaction is that the transaction can fail before finishing the all the operations in the set. part of the database system, since it enables the database to handle data sizes that are much larger than the size of main memory.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What causes deadlock?\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "adlock. If more then one process takes action , the deadlock detection algorithm can repeatedly trigger.\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "Live lock is also known as lived lock. Deadlock is also known as circular waiting.\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "Live lock is also known as lived lock. Deadlock is also known as circular waiting.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Explain B-tree index.\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "B+ Tree Index File\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "Advantages of B+-trees outweigh disadvantages, and are not required to maintain performance.\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "Advantages of B+-trees outweigh disadvantages, and are not required to maintain performance.\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: Difference between DELETE and TRUNCATE?\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "DELETE vs TRUNCATE\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "DROP TABLE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "DROP TABLE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE_NAME; DROP DATABASE TABLE\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is two-phase locking?\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "TWO-PHASE LOCKING\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "The lock is excusive in the sense that no other transaction can acquire any kind of lock (either shared or exclusive) on that same data item. The relationship between Shared and Exclusive Lock can be represented by the following table which is known as LockMatrix. Shared Exclusive Shared TRUE FALSE Exclusive FALSE Two Phase Locking Protocol:- The two-phase locking protocol defines the rules of how to acquire the locks on a data item and how to release the locks. The locks acquired by the transaction are obtained. The transaction enters into growing phase as soon as it acquires first lock. Once all locks have been acquired the transaction is in its locked point. Phase 2: Lock Release Phase\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "The lock is excusive in the sense that no other transaction can acquire any kind of lock (either shared or exclusive) on that same data item. The relationship between Shared and Exclusive Lock can be represented by the following table which is known as LockMatrix. Shared Exclusive Shared TRUE FALSE Exclusive FALSE Two Phase Locking Protocol:- The two-phase locking protocol defines the rules of how to acquire the locks on a data item and how to release the locks. The locks acquired by the transaction are obtained. The transaction enters into growing phase as soon as it acquires first lock. Once all locks have been acquired the transaction is in its locked point. Phase 2: Lock Release Phase\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: What is functional dependency?\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "a particular relationship between two attributes\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "Y\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "Y\n",
      "====================================================================================================\n",
      "\n",
      "QUESTION: When should we use hash index instead of B-tree?\n",
      "\n",
      "--- Top-k = 3 ---\n",
      "B+-Trees.\n",
      "\n",
      "--- Top-k = 5 ---\n",
      "a key that is not a key\n",
      "\n",
      "--- Top-k = 8 ---\n",
      "a key that is not a key\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for q in test_questions:\n",
    "    print(\"\\nQUESTION:\", q)\n",
    "    \n",
    "    print(\"\\n--- Top-k = 3 ---\")\n",
    "    print(generate_answer_k(q, k=3))\n",
    "    \n",
    "    print(\"\\n--- Top-k = 5 ---\")\n",
    "    print(generate_answer_k(q, k=5))\n",
    "    \n",
    "    print(\"\\n--- Top-k = 8 ---\")\n",
    "    print(generate_answer_k(q, k=8))\n",
    "    \n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc359dad-89eb-4bae-90dd-a8a9d16c870b",
   "metadata": {},
   "source": [
    "## Experiment 3 Results & Analysis\n",
    "\n",
    "After testing different top-k values (3, 5, and 8), I carefully observed the quality of answers.\n",
    "\n",
    "### Observations\n",
    "\n",
    "1. Top-k = 3\n",
    "   - Answers were short but mostly relevant.\n",
    "   - Less noise in context.\n",
    "   - However, some answers were incomplete (only definitions without explanation).\n",
    "\n",
    "2. Top-k = 5\n",
    "   - In some cases, answers became longer.\n",
    "   - But extra unrelated text started appearing.\n",
    "   - Some outputs included page numbers and random headings like:\n",
    "     \"DATABASE MANAGEMENT SYSTEMS Page 125\"\n",
    "   - This shows retrieval is bringing unnecessary chunks.\n",
    "\n",
    "3. Top-k = 8\n",
    "   - Too much irrelevant context.\n",
    "   - Model got confused.\n",
    "   - Repetitions and garbage outputs increased.\n",
    "   - In some questions, answer quality actually degraded.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "Increasing top-k does NOT always improve answer quality.\n",
    "\n",
    "In fact:\n",
    "- Too small k → Missing context\n",
    "- Too large k → Too much noise\n",
    "- Balanced k → Better performance\n",
    "\n",
    "In my case, top-k = 3 performed more stable compared to 5 and 8.\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Happened\n",
    "\n",
    "The main issue is document cleanliness.\n",
    "\n",
    "My PDFs contain:\n",
    "- Page numbers\n",
    "- Headers and footers\n",
    "- Repeated lines\n",
    "- Broken formatting\n",
    "\n",
    "When k increases, these noisy chunks also get retrieved, which confuses the model.\n",
    "\n",
    "So retrieval quality matters more than quantity.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "For my DBMS documents:\n",
    "\n",
    "- Top-k = 3 gives cleaner and more focused answers.\n",
    "- Increasing k beyond 5 adds more noise than value.\n",
    "- Retrieval quality is more important than just retrieving more chunks.\n",
    "\n",
    "For final system, I will use:\n",
    "→ top-k = 3 (for cleaner and more stable responses)\n",
    "\n",
    "If I had more time, I would:\n",
    "- Clean the extracted text better\n",
    "- Remove page numbers and repeated headers\n",
    "- Use re-ranking instead of simple similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279ee15-3ce0-4ad8-b2f3-d552e9dc4293",
   "metadata": {},
   "source": [
    "# Part 4: Handling Real-World Challenges\n",
    "\n",
    "In this section, I address some practical challenges that occurred while building the RAG system using real DBMS course materials.\n",
    "\n",
    "Unlike clean tutorial datasets, academic PDFs contain formatting issues, tables, repeated headers, page numbers, and inconsistent structure. These issues directly affected retrieval quality and answer generation.\n",
    "\n",
    "I selected two major challenges from my dataset:\n",
    "\n",
    "1. Noisy text and formatting issues\n",
    "2. Loss of table and SQL structure during extraction\n",
    "\n",
    "Below I describe each problem, my solution, and the limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0da36c-e95b-4d20-9b49-984e7d4f2bd1",
   "metadata": {},
   "source": [
    "## Challenge 1: Noisy Text and Formatting Issues in PDFs\n",
    "\n",
    "### Problem Description\n",
    "\n",
    "While extracting text from DBMS PDFs using pdfplumber, I observed that the extracted text contained:\n",
    "\n",
    "- Repeated headers like \"DATABASE MANAGEMENT SYSTEMS\"\n",
    "- Page numbers such as \"Page 125\"\n",
    "- Broken line spacing\n",
    "- Random uppercase titles\n",
    "- Merged headings with paragraphs\n",
    "\n",
    "Example of raw extracted text:\n",
    "\n",
    "\"DATABASE MANAGEMENT SYSTEMS Page 125 UNIT-4 TRANSACTION MANAGEMENT IN DBMS: A transaction is a set of logically related operations...\"\n",
    "\n",
    "This extra noise affected the retrieval stage. When top-k was increased, many of these noisy chunks were retrieved instead of actual meaningful content. This confused the language model and degraded answer quality.\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Is a Real-World Problem\n",
    "\n",
    "In industry, documents are rarely clean. Academic notes, government reports, legal PDFs, and scanned documents often contain:\n",
    "\n",
    "- Headers and footers\n",
    "- Page numbering\n",
    "- Formatting inconsistencies\n",
    "- Repeated section titles\n",
    "\n",
    "If this noise is not removed, the RAG system retrieves irrelevant content, which reduces answer accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### My Solution\n",
    "\n",
    "I implemented a text cleaning function before chunking the documents.\n",
    "\n",
    "The cleaning steps included:\n",
    "\n",
    "1. Removing page numbers using regular expressions\n",
    "2. Removing repeated headers\n",
    "3. Reducing multiple newlines\n",
    "4. Removing extra spaces\n",
    "\n",
    "This ensured that only meaningful academic content was stored in the vector database.\n",
    "\n",
    "---\n",
    "\n",
    "### Impact on System Performance\n",
    "\n",
    "After cleaning:\n",
    "\n",
    "- Retrieved chunks became more focused.\n",
    "- Less irrelevant context was passed to the model.\n",
    "- Repetition reduced.\n",
    "- Answer clarity improved slightly.\n",
    "\n",
    "Although the improvement was not dramatic (due to model limitations), retrieval stability improved.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e210449-5c61-4669-a149-2eff9f0b1a52",
   "metadata": {},
   "source": [
    "## Challenge 2: Loss of Table and SQL Structure During Text Extraction\n",
    "\n",
    "### Problem Description\n",
    "\n",
    "DBMS subject contains:\n",
    "\n",
    "- SQL queries\n",
    "- Table structures\n",
    "- Attribute lists\n",
    "- Schema definitions\n",
    "- Lock compatibility tables\n",
    "- ACID property tables\n",
    "\n",
    "While extracting text using pdfplumber, I noticed that:\n",
    "\n",
    "- Tables lost column alignment\n",
    "- SQL queries lost indentation\n",
    "- Table rows were merged into single lines\n",
    "- Bullet formatting was broken\n",
    "- Some special symbols were removed\n",
    "\n",
    "Example issue:\n",
    "\n",
    "Original SQL in PDF:\n",
    "SELECT *  \n",
    "FROM Student  \n",
    "WHERE marks > 80;\n",
    "\n",
    "After extraction:\n",
    "SELECT * FROM Student WHERE marks > 80;\n",
    "\n",
    "In some cases, even worse formatting occurred where words merged together.\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Is a Real-World Problem\n",
    "\n",
    "RAG systems depend heavily on clean context.\n",
    "\n",
    "In DBMS:\n",
    "- SQL syntax structure matters.\n",
    "- Table column separation matters.\n",
    "- Lock matrix tables matter.\n",
    "\n",
    "If structure is lost:\n",
    "- The model may misunderstand relationships.\n",
    "- It may generate incomplete or incorrect explanations.\n",
    "- Retrieval may miss important structured information.\n",
    "\n",
    "This is common in real-world enterprise documents as well.\n",
    "\n",
    "---\n",
    "\n",
    "### My Current Handling Approach\n",
    "\n",
    "Since this assignment focuses on ML aspects rather than document engineering, I used the following practical approach:\n",
    "\n",
    "1. Accepted flattened SQL as plain text.\n",
    "2. Used smaller chunk sizes to avoid mixing multiple SQL blocks.\n",
    "3. Relied on semantic embeddings to capture meaning rather than formatting.\n",
    "\n",
    "This worked reasonably well for conceptual questions but struggled for syntax-heavy explanations.\n",
    "\n",
    "---\n",
    "\n",
    "### Impact on Answer Quality\n",
    "\n",
    "I observed:\n",
    "\n",
    "- Concept-based questions (e.g., normalization, ACID) worked better.\n",
    "- Structure-heavy questions (e.g., B-tree index, DELETE vs TRUNCATE differences) sometimes produced incomplete or confusing answers.\n",
    "- Retrieval sometimes picked only partial SQL or table descriptions.\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- SQL formatting is not preserved.\n",
    "- Table alignment is completely lost.\n",
    "- Diagrams (like ER models) are not captured.\n",
    "- No OCR handling for image-based content.\n",
    "\n",
    "---\n",
    "\n",
    "### What I Would Improve With More Time\n",
    "\n",
    "If building this as a real product, I would:\n",
    "\n",
    "- Use layout-aware PDF extraction tools\n",
    "- Detect and separately store SQL code blocks\n",
    "- Preserve table structure using structured parsers\n",
    "\n",
    "This experiment helped me understand that document preprocessing is one of the most critical components of any RAG system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3263c-73de-4ec0-929e-fda9716809a9",
   "metadata": {},
   "source": [
    "# Part 5: Final System & Reflection\n",
    "\n",
    "## 5.1 Final Production Version\n",
    "\n",
    "After performing multiple experiments on chunking strategies, prompting techniques, and retrieval configurations, I finalized the following system configuration for my DBMS RAG Study Assistant.\n",
    "\n",
    "### Final Configuration\n",
    "\n",
    "Embedding Model:\n",
    "- Sentence Transformers (all-MiniLM-L6-v2)\n",
    "\n",
    "Vector Database:\n",
    "- ChromaDB (embedded)\n",
    "\n",
    "Chunking Strategy:\n",
    "- Fixed-size chunking (500 characters with overlap)\n",
    "Reason: It gave more stable answers compared to sentence-based chunking.\n",
    "\n",
    "Retrieval Strategy:\n",
    "- Top-k = 3\n",
    "Reason: Higher values introduced noise from page numbers and formatting artifacts.\n",
    "\n",
    "Prompting Strategy:\n",
    "- Improved structured prompt\n",
    "Reason: It generated slightly more complete and focused answers compared to basic prompt.\n",
    "\n",
    "Language Model:\n",
    "- Open-source model (flan-t5-base)\n",
    "\n",
    "---\n",
    "\n",
    "### Why I Selected This Configuration\n",
    "\n",
    "From Experiment 1:\n",
    "Chunking strategy had significant impact on retrieval quality. Fixed chunking performed more consistently for my DBMS PDFs.\n",
    "\n",
    "From Experiment 2:\n",
    "Improved prompting provided slightly more structured responses, though improvement was limited due to model size.\n",
    "\n",
    "From Experiment 3:\n",
    "Increasing top-k did not improve answer quality. Instead, it introduced noise. Therefore, I selected top-k = 3.\n",
    "\n",
    "---\n",
    "\n",
    "### Final System Workflow\n",
    "\n",
    "1. Extract text from DBMS PDFs\n",
    "2. Clean noise (headers, page numbers)\n",
    "3. Apply fixed-size chunking\n",
    "4. Generate embeddings\n",
    "5. Store chunks in ChromaDB\n",
    "6. Retrieve top 3 relevant chunks\n",
    "7. Generate answer using improved prompt\n",
    "\n",
    "This configuration provides the most stable and balanced results within the constraints of free open-source models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b05f9-3be5-40ad-97e0-3df325b6f5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_env)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
